---
title: "statistics notebook"
output: html_notebook
---

# An ecologically-flavoured introduction to statistics - Day 1

## Goal
acquire an intuition about statistical methods: their nature, usage scenarios, and limitations

## literature
- Galileo Galilei - Il saggiatore
- Sally Calrdwell - Statisctics unplugged
- David Fredman, Robert Pisani, Roger Purves - Statistics
- Darrell Huff - How to lie with statistics
- Shannons theory of information (degree of surprise / contrast)

## Links
[mathematic symbols](https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html)
[rmarkdown cheatsheet](https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)


## Definitions
### Statistic
A numerical value which characterises the *sample* or *population* from which it was derived
$\rightarrow$ statistics is the study of the collection, analysis, interpretation, presentation, and organisation of data
### Population (sample set)
A complete set fo items that share at least one property in common that is the subject of a statistical analysis.
### Sample (event set)
A *limited number* of observations systematically or (pseudo)randomly selected from a population, whose analysis may yield generalisations about the source population. $\rightarrow$ must be representative
### Statistical estimator
The estimators estimate a population parameter based on sample data

- $\overline{x}$ estimates $\mu$
- $\mu$ is the population *mean*
- $\overline{x}$ is the sample *mean*
- a sample size of 3 is too small to calculate the mean

## Plan an experiment
Design your experiment with the data analysis in mind!

- minimum number if replicates needed $\rightarrow$ perform a power analysis
- disentangle the influence of confounding variables
- determine the statistical analyses that will be used
- one replicates a treatment/effect on an experimental unit
- the effect needs to be independet on one experimental unit
- replicates need to be independet on one another

## data types

- binary (logical)
- quantitative (discontinuous)
- quantitative (continuous)
- ordinal / ranked
- categorical / nominal (can be transformed with dummy numeric variables)

## Location of data
### Pythagorean means
- *the arithmetic mean*: $\overline{x}=\frac{1}{n}\sum_{i=1}^{n} x_{i}$
$\rightarrow$ often refered to as expected value E(X), where X is a random variable
- *the geometric mean*: $\sqrt[n]{\prod_{i=1}^{n} x_{i}}$
- *the harmonic mean*: $\overline{x}=n\sum_{i=1}^{n} \frac{1}{x_{i}}$
$\rightarrow$ inequality concerning AM, GM, and HM: $AM \ge GM \ge HM$

### Statistical location
- *the median*: order your data and take the middle value
- *the mode*: most commen value of a data series
$\rightarrow$ multiple modes possible: unimodal<bimodal<multimodal
$\rightarrow$ different distributions call for different measures of center! The arithmetic mean is not always valid!
- *skewness*: measure of symmetry
$\rightarrow$ negative (left) skewness: the mean of the data values is less than the median
$\rightarrow$ positive (right) skewness: the mean of the data values is larger than the median

## Spread of data

- *range*: highest - lowest value
- *sample variance*: $s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_{i}-\overline{x})^2$ 
$\rightarrow$ $s^2 \ge 0$
$\rightarrow$ $s^2 = 0$ all values are equal
- *standard deviation*: $s = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (x_{i}-\overline{x})^2}$
$\rightarrow$ standardised form of the variance
- *coefficient of variation*: $\frac{s}{\overline{x}}$
$\rightarrow$ used when comparing multiple samples with different means. Standardisation!
- *concept of central moments*: variance, skewness, and kurtosis are all related through this concept

# An ecologically-flavoured introduction to statistics - Day 2

*The Random Variable*
$\rightarrow$ a variable whose value varies according to chance
$\rightarrow$ each value has an assigned probability

## Normal distribution

- $X \sim N(\mu, \sigma)$
- only controlled by two variables
- *probability density funciton*: $P(X) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
- Even if each sample-derived ramdom variable in a large collection of random variables (from the same population) is non-Gaussian, their means are distributed normally!
$\rightarrow$ *central limit theorem*

## Data transformation

- $y' = my+b$
- $y' = \sqrt{y}$
- $y' = \log{y}$
- *Z-score*: $Z = \frac{x_{i}-\overline{x}}{S_{x}}$
$\rightarrow$ standardization! without units!
$\rightarrow$ Based on the normal distribution, standardises normal data to zero mean and unit variance

## Various Distributions
*The Student's t distribution*

n = ~ 30
$X \sim f(p_{1} \dots p_{n})$
$X \sim T(\nu)$
$\nu > 0$

*The Discrete Random Variable*
$\rightarrow$ probability mass function

*The Binomial Distribution*
$\rightarrow$ popular discrete variables
$\rightarrow$ Bernoulli distribution: yes / no results

n: number of trials !!!
$\rightarrow$ the one complement: q = 1-p

*The Poisson Distribution* 
$\rightarrow$ discrete probability mass function

## Character

*Covariance*
$\rightarrow$ how do the variances of two variables relate?

*Correlation*
$\rightarrow$ Pearson's coefficient: only linear correlation
- Cov(X,Y)/sx*sy
- cares about values
$\rightarrow$ Spearman's rank coefficient: 
- gives the data ranks
- useful for ordinal data

*Linear Regression*
- y = mx + b
- x is the explainatory factor (independent variable)
- y is the response (dependent variable)
- m is the slope
- b is the intercept

- R2: How much covariation does this model explain
- residual: difference between predicted and observed values






